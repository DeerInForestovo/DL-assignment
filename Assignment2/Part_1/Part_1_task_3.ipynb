{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1\n",
    "\n",
    "## Task 3\n",
    "\n",
    "### Data loading\n",
    "\n",
    "We use several methods to preprocess the data.\n",
    "\n",
    "1. ```transforms.RandomHorizontalFlip()```: This randomly flips each image horizontally to augment the dataset by creating variations of the images.\n",
    "2. ```transforms.RandomCrop(32, padding=4)```: This crops the image to a 32x32 size with a padding of 4 pixels, which adds randomness to the dataset by simulating slight shifts.\n",
    "3. ```transforms.ToTensor()```: Convert to tensor.\n",
    "4. ```transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))```: This normalizes the image tensor using the mean (0.4914, 0.4822, 0.4465) and standard deviation (0.2470, 0.2435, 0.2616) for each RGB channel, which are the computed means and standard deviations of the CIFAR-10 dataset. Parameters referred https://stackoverflow.com/questions/69747119/pytorch-cifar10-images-are-not-normalized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523afd24343f2a02"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from MLPnet import MLPnet\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T12:12:10.900575600Z",
     "start_time": "2024-11-10T12:12:07.216287200Z"
    }
   },
   "id": "2ba7b4f2e9d45aea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The model, the criterion and the optimizer\n",
    "\n",
    "The model, see ```MLPnet.py```, added two units into MLP:\n",
    "\n",
    "1. ```BatchNormalization```: reduces internal covariate shift.\n",
    "2. ```Dropout```: randomly sets the output of some neurons in the neural network to zero. This operation makes the model independent of specific neurons or feature combinations during training.\n",
    "\n",
    "The ```weight_decay``` is used to avoid overfitting."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9fa54091fc081f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = MLPnet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T12:12:10.937588800Z",
     "start_time": "2024-11-10T12:12:10.901575600Z"
    }
   },
   "id": "164f30a54563dd42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ea54f0445a42cc5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.9003, Validation Accuracy: 0.3791\n",
      "Epoch [2/20], Loss: 1.7231, Validation Accuracy: 0.4162\n",
      "Epoch [3/20], Loss: 1.6469, Validation Accuracy: 0.4378\n",
      "Epoch [4/20], Loss: 1.6076, Validation Accuracy: 0.4413\n",
      "Epoch [5/20], Loss: 1.5758, Validation Accuracy: 0.4534\n",
      "Epoch [6/20], Loss: 1.5494, Validation Accuracy: 0.4565\n",
      "Epoch [7/20], Loss: 1.5284, Validation Accuracy: 0.4670\n",
      "Epoch [8/20], Loss: 1.5102, Validation Accuracy: 0.4782\n",
      "Epoch [9/20], Loss: 1.4980, Validation Accuracy: 0.4752\n",
      "Epoch [10/20], Loss: 1.4825, Validation Accuracy: 0.4851\n",
      "Epoch [11/20], Loss: 1.4679, Validation Accuracy: 0.4846\n",
      "Epoch [12/20], Loss: 1.4543, Validation Accuracy: 0.4915\n",
      "Epoch [13/20], Loss: 1.4465, Validation Accuracy: 0.5022\n",
      "Epoch [14/20], Loss: 1.4359, Validation Accuracy: 0.4965\n",
      "Epoch [15/20], Loss: 1.4258, Validation Accuracy: 0.5037\n",
      "Epoch [16/20], Loss: 1.4164, Validation Accuracy: 0.4967\n",
      "Epoch [17/20], Loss: 1.4040, Validation Accuracy: 0.5221\n",
      "Epoch [18/20], Loss: 1.4059, Validation Accuracy: 0.5114\n",
      "Epoch [19/20], Loss: 1.3903, Validation Accuracy: 0.5070\n",
      "Epoch [20/20], Loss: 1.3831, Validation Accuracy: 0.5163\n",
      "Test Accuracy: 0.5173\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
    "test(model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T12:18:51.817024500Z",
     "start_time": "2024-11-10T12:12:10.934587Z"
    }
   },
   "id": "31be6bd1905c0a35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
